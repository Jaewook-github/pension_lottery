#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì—°ê¸ˆë³µê¶Œ ë‹¹ì²¨ë²ˆí˜¸ í¬ë¡¤ë§ ìŠ¤í¬ë¦½íŠ¸
ë™í–‰ë³µê¶Œ ì‚¬ì´íŠ¸ì—ì„œ ì—°ê¸ˆë³µê¶Œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ CSV/JSONìœ¼ë¡œ ì €ì¥
"""

import requests
from bs4 import BeautifulSoup
import csv
import json
import time
import logging
from datetime import datetime
import os
import re


class PensionLotteryCrawler:
    def __init__(self):
        """í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”"""
        self.base_url = "https://www.dhlottery.co.kr"
        self.pension_url = f"{self.base_url}/gameResult.do?method=byWin&wiselog=H_C_1_1&drwNo="
        self.session = requests.Session()

        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.data_dir = 'lottery_data'
        os.makedirs(self.data_dir, exist_ok=True)
        os.makedirs('logs', exist_ok=True)

        # ë¡œê¹… ì„¤ì •
        log_filename = f"logs/crawling_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_filename, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)

        # í—¤ë” ì„¤ì •
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })

        self.data = []

    def get_latest_round(self):
        """ìµœì‹  íšŒì°¨ ë²ˆí˜¸ ê°€ì ¸ì˜¤ê¸°"""
        try:
            response = self.session.get(f"{self.base_url}/gameResult.do?method=byWin")
            response.raise_for_status()

            soup = BeautifulSoup(response.text, 'html.parser')

            # íšŒì°¨ ë²ˆí˜¸ ì°¾ê¸° (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)
            selectors = [
                'select[name="drwNo"] option:first-child',
                '.win_result .title strong',
                '#article .title'
            ]

            for selector in selectors:
                element = soup.select_one(selector)
                if element:
                    text = element.get_text()
                    numbers = re.findall(r'\d+', text)
                    if numbers:
                        latest_round = int(numbers[0])
                        self.logger.info(f"ìµœì‹  íšŒì°¨ í™•ì¸: {latest_round}íšŒ")
                        return latest_round

            # ê¸°ë³¸ê°’ìœ¼ë¡œ í˜„ì¬ íšŒì°¨ ì¶”ì •
            current_year = datetime.now().year
            weeks_passed = (datetime.now() - datetime(current_year, 1, 1)).days // 7
            estimated_round = (current_year - 2021) * 52 + weeks_passed

            self.logger.warning(f"ìµœì‹  íšŒì°¨ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì¶”ì •ê°’ ì‚¬ìš©: {estimated_round}íšŒ")
            return estimated_round

        except Exception as e:
            self.logger.error(f"ìµœì‹  íšŒì°¨ í™•ì¸ ì‹¤íŒ¨: {e}")
            return 1000  # ê¸°ë³¸ê°’

    def crawl_round(self, round_num):
        """íŠ¹ì • íšŒì°¨ ë°ì´í„° í¬ë¡¤ë§"""
        try:
            url = f"{self.pension_url}{round_num}"
            response = self.session.get(url)
            response.raise_for_status()

            soup = BeautifulSoup(response.text, 'html.parser')

            # ë‹¹ì²¨ë²ˆí˜¸ ì¶”ì¶œ ì‹œë„
            round_data = self._extract_winning_numbers(soup, round_num)

            if round_data:
                self.data.append(round_data)
                return True
            else:
                self.logger.warning(f"{round_num}íšŒ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False

        except Exception as e:
            self.logger.error(f"{round_num}íšŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return False

    def _extract_winning_numbers(self, soup, round_num):
        """HTMLì—ì„œ ë‹¹ì²¨ë²ˆí˜¸ ì¶”ì¶œ"""
        try:
            # ë‹¤ì–‘í•œ ì…€ë ‰í„°ë¡œ ë‹¹ì²¨ë²ˆí˜¸ ì°¾ê¸°
            selectors = [
                '.win_result .num',
                '.lotto_num',
                '.winner_number',
                'span.ball_645'
            ]

            winning_numbers = []
            for selector in selectors:
                numbers = soup.select(selector)
                if numbers:
                    for num in numbers:
                        text = num.get_text().strip()
                        if text.isdigit():
                            winning_numbers.append(text)
                    break

            if not winning_numbers:
                # í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì íŒ¨í„´ ì°¾ê¸°
                text = soup.get_text()
                patterns = [
                    r'ë‹¹ì²¨ë²ˆí˜¸.*?(\d{6})',
                    r'(\d{6})',
                    r'ë²ˆí˜¸.*?(\d{6})'
                ]

                for pattern in patterns:
                    matches = re.findall(pattern, text)
                    if matches:
                        winning_numbers = matches
                        break

            if winning_numbers and len(winning_numbers) >= 1:
                # 1ë“± ë‹¹ì²¨ë²ˆí˜¸ (6ìë¦¬)
                first_number = winning_numbers[0].zfill(6)

                # 2ë“± ë‹¹ì²¨ë²ˆí˜¸ (ë³´í†µ ëìë¦¬ ë²ˆí˜¸)
                second_number = '0'  # ê¸°ë³¸ê°’
                if len(winning_numbers) > 1:
                    second_number = winning_numbers[1][-1]  # ë§ˆì§€ë§‰ ìë¦¬
                elif len(first_number) == 6:
                    second_number = first_number[-1]  # 1ë“± ë²ˆí˜¸ì˜ ë§ˆì§€ë§‰ ìë¦¬

                # ì¡° ê³„ì‚° (1ë“± ë²ˆí˜¸ ì•ìë¦¬ë¡œ)
                jo = int(first_number[0]) if first_number[0] != '0' else 1
                if jo > 5:
                    jo = jo % 5 + 1

                return {
                    'round': round_num,
                    'first_number': first_number,
                    'second_number': second_number,
                    'jo': jo,
                    'crawl_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }

            return None

        except Exception as e:
            self.logger.error(f"ë‹¹ì²¨ë²ˆí˜¸ ì¶”ì¶œ ì‹¤íŒ¨ (round {round_num}): {e}")
            return None

    def save_to_csv(self, filename='pension_lottery_all.csv'):
        """CSV íŒŒì¼ë¡œ ì €ì¥"""
        filepath = os.path.join(self.data_dir, filename)

        try:
            with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:
                if self.data:
                    fieldnames = self.data[0].keys()
                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                    writer.writeheader()
                    writer.writerows(self.data)

            self.logger.info(f"CSV ì €ì¥ ì™„ë£Œ: {filepath} ({len(self.data)}ê°œ íšŒì°¨)")

        except Exception as e:
            self.logger.error(f"CSV ì €ì¥ ì‹¤íŒ¨: {e}")

    def save_to_json(self, filename='pension_lottery_all.json'):
        """JSON íŒŒì¼ë¡œ ì €ì¥"""
        filepath = os.path.join(self.data_dir, filename)

        try:
            with open(filepath, 'w', encoding='utf-8') as jsonfile:
                json.dump(self.data, jsonfile, ensure_ascii=False, indent=2)

            self.logger.info(f"JSON ì €ì¥ ì™„ë£Œ: {filepath} ({len(self.data)}ê°œ íšŒì°¨)")

        except Exception as e:
            self.logger.error(f"JSON ì €ì¥ ì‹¤íŒ¨: {e}")

    def load_existing_data(self):
        """ê¸°ì¡´ ë°ì´í„° ë¡œë“œ"""
        csv_file = os.path.join(self.data_dir, 'pension_lottery_all.csv')

        if os.path.exists(csv_file):
            try:
                with open(csv_file, 'r', encoding='utf-8') as csvfile:
                    reader = csv.DictReader(csvfile)
                    self.data = list(reader)

                    # ë°ì´í„° íƒ€ì… ë³€í™˜
                    for row in self.data:
                        row['round'] = int(row['round'])
                        row['jo'] = int(row['jo'])

                self.logger.info(f"ê¸°ì¡´ ë°ì´í„° ë¡œë“œ: {len(self.data)}ê°œ íšŒì°¨")
                return True

            except Exception as e:
                self.logger.error(f"ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.data = []
                return False

        return False

    def get_missing_rounds(self, latest_round):
        """ëˆ„ë½ëœ íšŒì°¨ ì°¾ê¸°"""
        existing_rounds = set()
        if self.data:
            existing_rounds = {int(row['round']) for row in self.data}

        all_rounds = set(range(1, latest_round + 1))
        missing_rounds = sorted(all_rounds - existing_rounds)

        return missing_rounds

    def crawl_all(self, start_round=1, end_round=None, delay=1):
        """ì „ì²´ íšŒì°¨ í¬ë¡¤ë§"""
        self.logger.info("=== ì—°ê¸ˆë³µê¶Œ í¬ë¡¤ë§ ì‹œì‘ ===")

        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
        self.load_existing_data()

        # ìµœì‹  íšŒì°¨ í™•ì¸
        if end_round is None:
            end_round = self.get_latest_round()

        # ëˆ„ë½ëœ íšŒì°¨ ì°¾ê¸°
        missing_rounds = self.get_missing_rounds(end_round)

        if not missing_rounds:
            self.logger.info("ëª¨ë“  ë°ì´í„°ê°€ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤.")
            return True

        self.logger.info(f"í¬ë¡¤ë§í•  íšŒì°¨: {len(missing_rounds)}ê°œ ({min(missing_rounds)}~{max(missing_rounds)})")

        success_count = 0
        total_count = len(missing_rounds)

        for i, round_num in enumerate(missing_rounds, 1):
            self.logger.info(f"[{i}/{total_count}] {round_num}íšŒ í¬ë¡¤ë§ ì¤‘...")

            if self.crawl_round(round_num):
                success_count += 1

                # ì¤‘ê°„ ì €ì¥ (10íšŒì°¨ë§ˆë‹¤)
                if success_count % 10 == 0:
                    self.save_to_csv()
                    self.save_to_json()
                    self.logger.info(f"ì¤‘ê°„ ì €ì¥ ì™„ë£Œ: {success_count}ê°œ íšŒì°¨")

            # ì„œë²„ ë¶€í•˜ ë°©ì§€
            if delay > 0:
                time.sleep(delay)

        # ìµœì¢… ì €ì¥
        if self.data:
            # íšŒì°¨ìˆœ ì •ë ¬
            self.data.sort(key=lambda x: int(x['round']))
            self.save_to_csv()
            self.save_to_json()

        self.logger.info(f"=== í¬ë¡¤ë§ ì™„ë£Œ ===")
        self.logger.info(f"ì„±ê³µ: {success_count}/{total_count}ê°œ íšŒì°¨")
        self.logger.info(f"ì „ì²´ ë°ì´í„°: {len(self.data)}ê°œ íšŒì°¨")

        return success_count > 0


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    crawler = PensionLotteryCrawler()

    try:
        # ì „ì²´ í¬ë¡¤ë§ ì‹¤í–‰
        success = crawler.crawl_all(delay=1)

        if success:
            print("\nğŸ‰ í¬ë¡¤ë§ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            print(f"ğŸ“ ì €ì¥ëœ íŒŒì¼:")
            print(f"   - lottery_data/pension_lottery_all.csv")
            print(f"   - lottery_data/pension_lottery_all.json")
            print(f"ğŸ“Š ì´ {len(crawler.data)}ê°œ íšŒì°¨ ë°ì´í„° ìˆ˜ì§‘")
        else:
            print("âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

    except KeyboardInterrupt:
        print("\nâ¹ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        crawler.save_to_csv()
        crawler.save_to_json()
        print("í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    main()